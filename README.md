# Langchain RAG

A Retrieval-Augmented Generation (RAG) system built with LangChain and Gemini AI.

## Features

- ğŸ” Document ingestion and processing
- ğŸ¤– LLM-powered question answering
- ğŸ“š Vector embeddings and semantic search
- ğŸ”— LangChain integration
- âš¡ Fast retrieval and response generation

## Installation

```bash
# Clone the repository
git clone https://github.com/Divinekrishna/langchain-rag.git
cd langchain-rag

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Setup

1. Create a `.env` file in the project root:
```
GEMINI_API_KEY=your_api_key_here
```

2. Run the application:
```bash
streamlit run app.py
```

## Project Structure

```
langchain-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ llm_handler.py
â”‚   â”‚   â”œâ”€â”€ document_handler.py
â”‚   â”‚   â””â”€â”€ rag_system.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Usage

[Coming soon...]

## License

MIT
